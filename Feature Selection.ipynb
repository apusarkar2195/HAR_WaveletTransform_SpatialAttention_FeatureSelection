{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bDbSCG0g6ME",
    "outputId": "15fb20c6-0a7c-4926-8f4a-7ad258234adb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: skfeature-chappers in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (1.1.0)\n",
      "Requirement already satisfied: pandas in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from skfeature-chappers) (1.4.3)\n",
      "Requirement already satisfied: numpy in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from skfeature-chappers) (1.23.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from skfeature-chappers) (1.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from pandas->skfeature-chappers) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from pandas->skfeature-chappers) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from scikit-learn->skfeature-chappers) (1.9.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from scikit-learn->skfeature-chappers) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from scikit-learn->skfeature-chappers) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->skfeature-chappers) (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install skfeature-chappers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "from skfeature.function.similarity_based import fisher_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PJ5varsMwJ_b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (3.5.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib) (1.23.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib) (4.34.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install matplotlib\n",
    "import random\n",
    "import math,time,sys, os\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WfQi7p_YoUQ6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1    2    3    4    5    6    7          8    9        10  ...  1015  \\\n",
      "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.000000  0.0  0.000000  ...   0.0   \n",
      "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.000000  0.0  0.000000  ...   0.0   \n",
      "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0   1.339774  0.0  0.000000  ...   0.0   \n",
      "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.000000  0.0  1.253475  ...   0.0   \n",
      "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.000000  0.0  6.962507  ...   0.0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...        ...  ...       ...  ...   ...   \n",
      "21244  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.116161  0.0  0.000000  ...   0.0   \n",
      "21245  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.000000  0.0  0.000000  ...   0.0   \n",
      "21246  0.0  0.0  0.0  0.0  0.0  0.0  0.0   1.324249  0.0  0.000000  ...   0.0   \n",
      "21247  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.000000  0.0  0.000000  ...   0.0   \n",
      "21248  0.0  0.0  0.0  0.0  0.0  0.0  0.0  11.792128  0.0  0.000000  ...   0.0   \n",
      "\n",
      "       1016  1017  1018  1019  1020  1021  1022  1023  1024  \n",
      "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "21244   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "21245   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "21246   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "21247   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "21248   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[21249 rows x 1024 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21244</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21245</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21246</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21247</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21248</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21249 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       # label\n",
       "0            8\n",
       "1           10\n",
       "2            2\n",
       "3            0\n",
       "4            2\n",
       "...        ...\n",
       "21244        1\n",
       "21245        1\n",
       "21246        9\n",
       "21247       11\n",
       "21248        6\n",
       "\n",
       "[21249 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_train=pd.read_csv('PAMPA_Train_Feature.csv')\n",
    "#dataframe_train.drop(dataframe_train.tail(1).index,inplace=True)\n",
    "dataframe_train = dataframe_train.iloc[: , 1:]\n",
    "print(dataframe_train)\n",
    "y_train=pd.read_csv('PAMPA2_Train_Label.csv')\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EJUuJkq39Zdd"
   },
   "outputs": [],
   "source": [
    "coln=dataframe_train.columns\n",
    "coln1=y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 906
    },
    "id": "vT_CMCmroxI6",
    "outputId": "a353c21c-b177-4760-d1c7-93e4246c7ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1         2    3    4    5    6    7         8    9        10  ...  \\\n",
      "0     0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   \n",
      "1     0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  4.289337  ...   \n",
      "2     0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.862526  ...   \n",
      "3     0.0  2.215433  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   \n",
      "4     0.0  0.000000  0.0  0.0  0.0  0.0  0.0  6.325282  0.0  0.000000  ...   \n",
      "...   ...       ...  ...  ...  ...  ...  ...       ...  ...       ...  ...   \n",
      "9102  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   \n",
      "9103  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   \n",
      "9104  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   \n",
      "9105  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   \n",
      "9106  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   \n",
      "\n",
      "      1015  1016  1017  1018  1019  1020  1021  1022  1023  1024  \n",
      "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "9102   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9103   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9104   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9105   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9106   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[9107 rows x 1024 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9104</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9105</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9106</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9107 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # label\n",
       "0           9\n",
       "1           0\n",
       "2           0\n",
       "3           2\n",
       "4           6\n",
       "...       ...\n",
       "9102        4\n",
       "9103        5\n",
       "9104        4\n",
       "9105       11\n",
       "9106        8\n",
       "\n",
       "[9107 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_test=pd.read_csv('PAMPA2_Test_Feature.csv')\n",
    "#dataframe_test.drop(dataframe_test.tail(1).index,inplace=True)\n",
    "dataframe_test = dataframe_test.iloc[: , 1:]\n",
    "print(dataframe_test)\n",
    "y_test=pd.read_csv('PAMPA2_Test_Label.csv')\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "o36finXw-BTZ"
   },
   "outputs": [],
   "source": [
    "dataframe_test.columns=coln\n",
    "y_test.columns=coln1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 906
    },
    "id": "Yq1CmriuhYWv",
    "outputId": "05f80acf-0a97-4070-aa12-2b3d80bd0b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1    2    3    4    5    6    7         8    9        10  ...  1015  \\\n",
      "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   0.0   \n",
      "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   0.0   \n",
      "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.339774  0.0  0.000000  ...   0.0   \n",
      "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  1.253475  ...   0.0   \n",
      "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  6.962507  ...   0.0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...       ...  ...       ...  ...   ...   \n",
      "30351  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   0.0   \n",
      "30352  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   0.0   \n",
      "30353  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   0.0   \n",
      "30354  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   0.0   \n",
      "30355  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000  ...   0.0   \n",
      "\n",
      "       1016  1017  1018  1019  1020  1021  1022  1023  1024  \n",
      "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "30351   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "30352   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "30353   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "30354   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "30355   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[30356 rows x 1024 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mm/5x1dmlhj75q0js87cstkgdhm0000gr/T/ipykernel_1318/831249703.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataframe=dataframe_train.append(dataframe_test,ignore_index=True)\n",
      "/var/folders/mm/5x1dmlhj75q0js87cstkgdhm0000gr/T/ipykernel_1318/831249703.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y=y_train.append(y_test,ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30351</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30352</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30353</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30354</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30355</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30356 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       # label\n",
       "0            8\n",
       "1           10\n",
       "2            2\n",
       "3            0\n",
       "4            2\n",
       "...        ...\n",
       "30351        4\n",
       "30352        5\n",
       "30353        4\n",
       "30354       11\n",
       "30355        8\n",
       "\n",
       "[30356 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=dataframe_train.append(dataframe_test,ignore_index=True)\n",
    "print(dataframe)\n",
    "y=y_train.append(y_test,ignore_index=True)\n",
    "y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgnBysKSFliu",
    "outputId": "ca0f985d-5ec6-4b9a-d59d-fcf2aee376cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n"
     ]
    }
   ],
   "source": [
    "cols=[]\n",
    "for i in range(len(dataframe.columns)):\n",
    "  col1=dataframe[dataframe.columns[i]].to_numpy()\n",
    "  if(np.sum(col1)==0):\n",
    "    cols.append(dataframe.columns[i])\n",
    "\n",
    "dataframe = dataframe.drop(columns=cols)\n",
    "print(dataframe.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "hInQdiIeiZIz",
    "outputId": "78fbbafc-52f1-43a1-dc17-ab1cb6e69a58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1005</th>\n",
       "      <th>1009</th>\n",
       "      <th>1010</th>\n",
       "      <th>1011</th>\n",
       "      <th>1014</th>\n",
       "      <th>1016</th>\n",
       "      <th>1019</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.264911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.339774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.253475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.962507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.038365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30351</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30352</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.674616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30353</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30354</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.418333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30355</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.231628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.610714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30356 rows Ã— 350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2         8    9        10   11   12   13        15        17  \\\n",
       "0      0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.808711   \n",
       "1      0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.392257  0.000000   \n",
       "2      0.0  1.339774  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
       "3      0.0  0.000000  0.0  1.253475  0.0  0.0  0.0  0.000000  0.000000   \n",
       "4      0.0  0.000000  0.0  6.962507  0.0  0.0  0.0  0.000000  0.000000   \n",
       "...    ...       ...  ...       ...  ...  ...  ...       ...       ...   \n",
       "30351  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
       "30352  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
       "30353  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
       "30354  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  2.418333  0.000000   \n",
       "30355  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  3.231628   \n",
       "\n",
       "             18  ...  1001  1002      1005  1009  1010  1011  1014  1016  \\\n",
       "0      0.000000  ...   0.0   0.0  3.264911   0.0   0.0   0.0   0.0   0.0   \n",
       "1      0.000000  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "2      0.000000  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "3      0.000000  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "4      0.000000  ...   0.0   0.0  1.038365   0.0   0.0   0.0   0.0   0.0   \n",
       "...         ...  ...   ...   ...       ...   ...   ...   ...   ...   ...   \n",
       "30351  0.000000  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "30352  1.674616  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "30353  0.000000  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "30354  0.000000  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "30355  0.000000  ...   0.0   0.0  5.610714   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "       1019  labels  \n",
       "0       0.0       8  \n",
       "1       0.0      10  \n",
       "2       0.0       2  \n",
       "3       0.0       0  \n",
       "4       0.0       2  \n",
       "...     ...     ...  \n",
       "30351   0.0       4  \n",
       "30352   0.0       5  \n",
       "30353   0.0       4  \n",
       "30354   0.0      11  \n",
       "30355   0.0       8  \n",
       "\n",
       "[30356 rows x 350 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=dataframe.copy()\n",
    "df['labels']=y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2rhpe6UBinf1"
   },
   "outputs": [],
   "source": [
    "x=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elGlCPM6it-4",
    "outputId": "794b620a-6305-42d9-cb95-fb741de8ba2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2         8    9        10   11   12   13        15        17  \\\n",
      "0      0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.808711   \n",
      "1      0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.392257  0.000000   \n",
      "2      0.0  1.339774  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
      "3      0.0  0.000000  0.0  1.253475  0.0  0.0  0.0  0.000000  0.000000   \n",
      "4      0.0  0.000000  0.0  6.962507  0.0  0.0  0.0  0.000000  0.000000   \n",
      "...    ...       ...  ...       ...  ...  ...  ...       ...       ...   \n",
      "30351  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
      "30352  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
      "30353  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
      "30354  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  2.418333  0.000000   \n",
      "30355  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.000000  3.231628   \n",
      "\n",
      "             18  ...  1001  1002      1005  1009  1010  1011  1014  1016  \\\n",
      "0      0.000000  ...   0.0   0.0  3.264911   0.0   0.0   0.0   0.0   0.0   \n",
      "1      0.000000  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
      "2      0.000000  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
      "3      0.000000  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
      "4      0.000000  ...   0.0   0.0  1.038365   0.0   0.0   0.0   0.0   0.0   \n",
      "...         ...  ...   ...   ...       ...   ...   ...   ...   ...   ...   \n",
      "30351  0.000000  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
      "30352  1.674616  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
      "30353  0.000000  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
      "30354  0.000000  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
      "30355  0.000000  ...   0.0   0.0  5.610714   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "       1019  labels  \n",
      "0       0.0       8  \n",
      "1       0.0      10  \n",
      "2       0.0       2  \n",
      "3       0.0       0  \n",
      "4       0.0       2  \n",
      "...     ...     ...  \n",
      "30351   0.0       4  \n",
      "30352   0.0       5  \n",
      "30353   0.0       4  \n",
      "30354   0.0      11  \n",
      "30355   0.0       8  \n",
      "\n",
      "[30356 rows x 350 columns]\n"
     ]
    }
   ],
   "source": [
    "ln=df.shape[1]\n",
    "str=df.columns[ln-1]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRnmALtbi73y",
    "outputId": "d125b9db-0a12-44a1-82b6-2f98455f9ceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 1.3397741, 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       ...,\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x.drop([str],axis=1)\n",
    "dataset=x.to_numpy()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "M4gc_IPTTslG"
   },
   "outputs": [],
   "source": [
    "def sort_agents(agents, obj,train_X,val_X,train_Y,val_Y):\n",
    "    # sort the agents according to fitness\n",
    "    #train_X, val_X, train_Y, val_Y = data.train_X, data.val_X, data.train_Y, data.val_Y\n",
    "    (obj_function, weight_acc) = obj\n",
    "\n",
    "    # if there is only one agent\n",
    "    if len(agents.shape) == 1:\n",
    "        num_agents = 1\n",
    "        fitness = obj_function(agents, train_X, val_X, train_Y, val_Y, weight_acc)\n",
    "        return agents, fitness\n",
    "\n",
    "    # for multiple agents\n",
    "    else:\n",
    "        num_agents = agents.shape[0]\n",
    "        fitness = np.zeros(num_agents)\n",
    "        for id, agent in enumerate(agents):\n",
    "            fitness[id] = obj_function(agent, train_X, val_X, train_Y, val_Y, weight_acc)\n",
    "            \n",
    "        idx = np.argsort(-fitness)\n",
    "        sorted_agents = agents[idx].copy()\n",
    "        sorted_fitness = fitness[idx].copy()\n",
    "        \n",
    "    return sorted_agents, sorted_fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1N_0QIWfbjjM"
   },
   "outputs": [],
   "source": [
    "def compute_fitness(agent, train_X, test_X, train_Y, test_Y, weight_acc=0.99):\n",
    "    # compute a basic fitness measure\n",
    "    if(weight_acc == None):\n",
    "        weight_acc = 0.99\n",
    "    \n",
    "    weight_feat = 1 - weight_acc\n",
    "    num_features = len(agent)\n",
    "   \n",
    "    acc = compute_accuracy(agent, train_X, test_X, train_Y, test_Y)\n",
    "    feat = (num_features - np.sum(agent))/num_features\n",
    "\n",
    "    fitness = weight_acc * acc + weight_feat * feat\n",
    "    \n",
    "    return fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "sNZ0PMXKVfDh",
    "outputId": "65cee72c-fb33-45a0-d4cf-703fa51d3e58"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# inputs:\n",
    "#    X: pandas.DataFrame, features\n",
    "#    yy: pandas.Series, target variable\n",
    "#    K: number of features to select\n",
    "\n",
    "\n",
    "X=x\n",
    "yy=df[str].to_numpy()\n",
    "K=x.shape[1]\n",
    "\n",
    "# compute F-statistics and initialize correlation matrix\n",
    "F = pd.Series(f_regression(X, yy)[0], index = X.columns)\n",
    "corr = pd.DataFrame(.00001, index = X.columns, columns = X.columns)\n",
    "\n",
    "# initialize list of selected features and list of excluded features\n",
    "selected = []\n",
    "not_selected = X.columns.to_list()\n",
    "Dict={}\n",
    "# repeat K times\n",
    "for i in range(K):\n",
    "  \n",
    "    # compute (absolute) correlations between the last selected feature and all the (currently) excluded features\n",
    "    if i > 0:\n",
    "        last_selected = selected[-1]\n",
    "        corr.loc[not_selected, last_selected] = X[not_selected].corrwith(X[last_selected]).abs().clip(.00001)\n",
    "        \n",
    "    # compute FCQ score for all the (currently) excluded features (this is Formula 2)\n",
    "    score = F.loc[not_selected] / corr.loc[not_selected, selected].mean(axis = 1).fillna(.00001)\n",
    "    \n",
    "    # find best feature, add it to selected and remove it from not_selected\n",
    "    # print(score[score.argmax()])\n",
    "    # print(score.max())\n",
    "    # print(score.index[score.argmax()])\n",
    "    best = score.index[score.argmax()]\n",
    "    selected.append(best)\n",
    "    not_selected.remove(best)\n",
    "    Dict[best]=score.max()\n",
    "\n",
    "mrMr=[]\n",
    "for i in range(x.shape[1]):\n",
    "  mrMr.append(Dict[x.columns[i]])\n",
    "#print(mrMr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3z5S32-0TPnw"
   },
   "outputs": [],
   "source": [
    "for i in range(len(mrMr)):\n",
    "  mrMr[i]=mrMr[i]/(max(mrMr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "MH8ovEhkHKb1"
   },
   "outputs": [],
   "source": [
    "def normalize(arr, t_min, t_max):\n",
    "    norm_arr = []\n",
    "    diff = t_max - t_min\n",
    "    diff_arr = max(arr) - min(arr)\n",
    "    for i in arr:\n",
    "        temp = (((i - min(arr))*diff)/diff_arr) + t_min\n",
    "        norm_arr.append(temp)\n",
    "    return norm_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaNhtfh2bcLS",
    "outputId": "5e6a578a-c4bc-48ce-823e-1b32730390ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Py-FS in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (0.0.44)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install Py-FS\n",
    "def fitness_score_values(data,target):\n",
    "    from Py_FS.filter import PCC as PCC\n",
    "    from Py_FS.filter import MI as MI\n",
    "    from sklearn.feature_selection import mutual_info_classif\n",
    "    from Py_FS.filter import Relief as Relief\n",
    "    from sklearn.feature_selection import chi2\n",
    "    \n",
    "    print(data)\n",
    "    print(target)\n",
    "    #print('Pcc scores')\n",
    "    #PCC_solution = PCC(data, target)\n",
    "    #print(PCC_solution.scores)\n",
    "    print('MI scores')\n",
    "    mi_scores=mutual_info_classif(data, target, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)\n",
    "    print((mi_scores))\n",
    "    \n",
    "    print('Relief scores')\n",
    "    Relief_solution = Relief(data, target)\n",
    "    print((Relief_solution.scores))\n",
    "    \n",
    "    \n",
    "        \n",
    "   \n",
    "    shapley=[]\n",
    "    b=x.shape[1]\n",
    "    print(b)\n",
    "    for i in range(b):\n",
    "        shapley.append((mi_scores[i]+mrMr[i]+Relief_solution.scores[i])/3)\n",
    "    return shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yM9pA5Mxv6Sn",
    "outputId": "f2569eec-f10e-4a70-cc18-6b5a4a5fe3e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 10  2 ...  4 11  8]\n"
     ]
    }
   ],
   "source": [
    "target=df[str].to_numpy()\n",
    "print(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hf1t7cWnIU3x",
    "outputId": "98140247-c992-4b7d-f737-a00c84b4a8cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (0.8.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ReliefF in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (0.1.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from ReliefF) (1.1.1)\n",
      "Requirement already satisfied: numpy in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from ReliefF) (1.23.1)\n",
      "Requirement already satisfied: scipy in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from ReliefF) (1.9.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from scikit-learn->ReliefF) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from scikit-learn->ReliefF) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "[[0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        1.3397741 0.        ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "MI scores\n",
      "[4.89956286e-02 9.22808786e-02 1.23656116e-02 5.57484491e-02\n",
      " 4.66296059e-03 9.42952052e-02 1.78161510e-03 1.55822332e-01\n",
      " 2.21300973e-01 2.50435190e-01 1.02936946e-01 1.20244572e-02\n",
      " 1.61534651e-01 2.78291046e-01 6.35706476e-02 1.25436165e-02\n",
      " 4.06808815e-03 2.54785107e-01 2.59625384e-01 2.39966366e-01\n",
      " 2.01051416e-01 2.17335638e-01 0.00000000e+00 2.63044913e-01\n",
      " 1.49263019e-02 5.74015000e-02 2.79128040e-01 1.03873210e-01\n",
      " 1.16459847e-01 7.25893937e-02 9.18624715e-02 6.51378097e-02\n",
      " 2.19650953e-01 9.80985186e-02 1.64928184e-03 2.39848967e-01\n",
      " 1.60062733e-01 3.10424967e-01 2.27263884e-02 1.52449723e-03\n",
      " 9.06718405e-02 7.00468382e-03 5.58405636e-01 5.28254110e-02\n",
      " 2.77379812e-01 2.59183205e-01 6.33631903e-02 1.22279303e-03\n",
      " 2.85579646e-01 1.18151381e-03 1.19194891e-02 0.00000000e+00\n",
      " 1.92554820e-02 6.32019389e-03 7.21409605e-02 1.17899542e-01\n",
      " 3.62520465e-01 5.87339902e-03 2.50395432e-01 1.91101371e-01\n",
      " 8.84908986e-03 3.08616280e-01 4.80792079e-02 1.25787961e-01\n",
      " 9.83486447e-03 8.62014025e-02 9.42667772e-02 2.85233378e-01\n",
      " 3.11472942e-01 4.50383755e-02 1.49908259e-01 9.50245437e-02\n",
      " 7.59912548e-02 9.45368153e-02 1.00234816e-02 2.16799128e-01\n",
      " 1.00057259e-01 3.05731921e-02 9.25222241e-02 3.82810396e-01\n",
      " 0.00000000e+00 1.34394863e-01 2.78818023e-01 8.48736455e-02\n",
      " 1.18426796e-01 0.00000000e+00 1.51528276e-01 1.17878709e-01\n",
      " 2.77704964e-01 1.94602695e-01 2.82777720e-01 2.64033708e-01\n",
      " 5.47072707e-02 5.06134318e-02 1.87604154e-01 6.58341670e-03\n",
      " 1.29627911e-01 6.50118530e-02 5.01804769e-02 8.01099839e-02\n",
      " 4.89544972e-02 5.83672171e-03 8.97064422e-02 3.32273109e-02\n",
      " 2.28665816e-01 3.12607483e-01 7.71840055e-02 1.94644328e-01\n",
      " 4.36759410e-03 2.70948290e-01 1.32998451e-01 2.31922991e-02\n",
      " 1.37456226e-01 2.35389812e-02 3.72051408e-01 4.35309583e-01\n",
      " 1.15063437e-03 4.64318258e-03 0.00000000e+00 1.04632479e-02\n",
      " 1.48991180e-01 8.21537771e-02 1.47514612e-02 7.27922347e-02\n",
      " 5.72615597e-01 7.31602998e-02 1.85750973e-01 3.24451585e-01\n",
      " 7.55096173e-04 0.00000000e+00 6.53508616e-02 6.94453799e-02\n",
      " 3.28624257e-01 3.64571136e-02 1.31431797e-01 1.92012655e-01\n",
      " 1.62893914e-01 1.30860884e-01 1.02594043e-01 0.00000000e+00\n",
      " 2.62458584e-03 2.79857345e-01 2.81113970e-01 2.52472471e-01\n",
      " 1.17482020e-01 3.79441450e-02 9.87706949e-03 3.83560759e-01\n",
      " 1.50286346e-01 4.16626185e-02 9.54725364e-02 3.42289633e-02\n",
      " 4.02964174e-02 0.00000000e+00 2.47035468e-01 1.23230983e-01\n",
      " 3.15769658e-01 6.84888365e-02 8.63662284e-02 3.11082482e-01\n",
      " 1.79339707e-02 0.00000000e+00 2.28230262e-01 1.19071081e-01\n",
      " 0.00000000e+00 1.84187585e-01 1.11019915e-01 1.60078545e-01\n",
      " 1.11350462e-01 2.58806746e-01 4.90652323e-02 4.26679861e-01\n",
      " 1.55804365e-01 0.00000000e+00 9.75010795e-02 4.44762500e-02\n",
      " 9.05072058e-03 9.37109573e-04 6.28687288e-02 1.52445873e-03\n",
      " 0.00000000e+00 3.91547887e-02 8.79978272e-02 2.20333234e-01\n",
      " 2.15456351e-01 5.16455470e-02 2.30261862e-01 7.87427743e-02\n",
      " 1.06014782e-02 1.41929579e-03 2.27246735e-01 2.42278328e-03\n",
      " 5.16630317e-03 1.78906212e-03 1.92789289e-01 1.36746375e-01\n",
      " 1.02774394e-01 1.59829992e-01 4.69600907e-01 9.35036244e-02\n",
      " 3.02955728e-01 1.37723569e-01 0.00000000e+00 6.34894900e-02\n",
      " 1.06278277e-01 3.95562532e-01 3.26315663e-01 2.26390060e-01\n",
      " 1.09329800e-01 2.15317808e-01 3.42790080e-02 7.64663084e-02\n",
      " 1.48183007e-01 4.03437337e-03 5.35579034e-02 4.84104527e-02\n",
      " 1.20708773e-01 1.31389903e-01 4.81101039e-02 1.48426741e-01\n",
      " 0.00000000e+00 1.57768086e-01 0.00000000e+00 1.97930026e-01\n",
      " 3.64566570e-01 4.53853370e-02 3.43096407e-01 1.53105516e-01\n",
      " 1.56769534e-01 1.04823358e-02 0.00000000e+00 4.64800472e-02\n",
      " 1.49676113e-01 3.12570841e-02 6.19001519e-03 3.54132120e-02\n",
      " 1.44461931e-01 1.00852195e-01 1.49910442e-01 3.16902601e-01\n",
      " 1.01487078e-02 8.15595464e-02 1.03857452e-01 2.07553898e-01\n",
      " 2.19911877e-02 1.92592088e-01 3.80271308e-03 2.49666464e-02\n",
      " 5.60293033e-02 3.72490721e-02 1.62274476e-01 2.36060531e-01\n",
      " 6.89431686e-02 9.59428796e-02 2.53535850e-01 3.86315255e-02\n",
      " 1.92932026e-02 2.93634224e-01 1.03928026e-01 1.19799985e-01\n",
      " 7.14034537e-02 1.05287465e-03 3.21977450e-02 6.31842826e-02\n",
      " 2.07440939e-01 5.68816187e-02 1.86561408e-01 2.07604269e-01\n",
      " 8.05341010e-02 2.00594965e-01 1.83783942e-01 5.41465665e-02\n",
      " 7.73606081e-03 1.89276082e-03 3.74628642e-01 1.41118320e-01\n",
      " 5.68782799e-02 0.00000000e+00 8.69674707e-02 1.80114992e-01\n",
      " 1.69986434e-02 4.63698154e-02 4.09453390e-02 3.13343998e-01\n",
      " 3.62614975e-01 1.06592397e-02 1.25923630e-02 7.30603950e-02\n",
      " 2.29247825e-01 5.67141140e-02 2.41362240e-01 2.71432678e-01\n",
      " 8.07255028e-02 1.78766652e-01 3.39699138e-04 7.57237571e-02\n",
      " 3.58991370e-02 5.42181064e-02 6.49752760e-02 9.45855481e-02\n",
      " 1.31852907e-01 3.47497183e-02 2.42614578e-02 4.22578059e-02\n",
      " 5.07923406e-03 0.00000000e+00 3.02598016e-02 3.29791339e-01\n",
      " 8.68531416e-02 1.63430975e-01 1.34156517e-01 1.82890882e-01\n",
      " 1.87148316e-01 2.91726712e-03 1.22059993e-01 0.00000000e+00\n",
      " 5.57391185e-02 2.02494808e-01 1.32403253e-01 8.67286998e-02\n",
      " 4.31991190e-03 2.32419183e-01 2.84214296e-01 9.33795406e-02\n",
      " 1.76564578e-02 1.07219191e-03 6.37470859e-04 0.00000000e+00\n",
      " 6.82983797e-02 9.59978373e-02 2.25501160e-01 1.41089477e-02\n",
      " 2.43331450e-01 1.85621277e-01 4.35712584e-01 3.15832158e-01\n",
      " 6.82374457e-02 7.38296307e-02 8.12256107e-03 1.08324896e-01\n",
      " 5.30699103e-03 0.00000000e+00 2.46036976e-01 1.72903279e-02\n",
      " 4.93961561e-04 7.22680079e-03 0.00000000e+00 0.00000000e+00\n",
      " 3.87044518e-03]\n",
      "Relief scores\n",
      "[0.88961307 0.68281731 0.98444258 0.812321   0.99638172 0.81009346\n",
      " 0.99996464 0.66185015 0.67232784 0.79458319 0.81804896 0.9945549\n",
      " 0.3477318  0.13012835 0.8202765  0.97971643 0.99684137 0.51873372\n",
      " 0.64685846 0.40332599 0.66193266 0.25702736 0.99882141 0.82525016\n",
      " 0.98738907 0.91593103 0.81998185 0.63965727 0.48404776 0.79402925\n",
      " 0.91720391 0.86661874 0.63135998 0.63458932 0.98747157 0.29516659\n",
      " 0.50522706 0.68007119 0.95830141 0.99903355 0.71390856 0.9999175\n",
      " 0.30709395 0.84519193 0.16657041 0.75586644 0.7316228  0.98564475\n",
      " 0.31719448 1.         0.99462562 0.99426026 0.97402383 0.9937181\n",
      " 0.79479534 0.55264181 0.52292951 0.99336453 0.657124   0.73842328\n",
      " 0.9989982  0.33613445 0.90770446 0.65799616 0.97387061 0.76404587\n",
      " 0.62671632 0.83393638 0.68799133 0.90421582 0.55009606 0.78345728\n",
      " 0.62630382 0.76716914 0.995651   0.60128231 0.82982309 0.87932396\n",
      " 0.57521185 0.40353813 0.99988214 0.65095996 0.82619303 0.7445991\n",
      " 0.75563072 0.99995286 0.74253657 0.74320836 0.81101276 0.40363242\n",
      " 0.68964135 0.8049548  0.91892465 0.82675875 0.64592738 0.9976546\n",
      " 0.72167549 0.83045953 0.85162705 0.7985079  0.89618961 0.98131932\n",
      " 0.81516141 0.96828409 0.29326906 0.30457176 0.89364385 0.73458107\n",
      " 0.99925749 0.83667071 0.68927599 0.96471295 0.64372341 0.963169\n",
      " 0.65661721 0.40420993 0.99938713 0.99252773 0.99972892 0.97958679\n",
      " 0.56779851 0.90134006 0.96269756 0.80329299 0.31127795 0.79526677\n",
      " 0.41649086 0.         0.99981143 1.         0.93425814 0.87257063\n",
      " 0.66399519 0.88747982 0.59063962 0.62532559 0.65330536 0.81754216\n",
      " 0.54573526 0.99987035 0.99620493 0.61653329 0.37060827 0.32907469\n",
      " 0.61087605 0.94886089 0.99987035 0.40085094 0.74105154 0.93596709\n",
      " 0.82525016 0.97272738 0.95778283 0.99959928 0.81926291 0.66742489\n",
      " 0.02294719 0.80329299 0.73421571 0.31713555 0.95630959 0.99952856\n",
      " 0.49680012 0.76348015 0.99971714 0.7451059  0.70736738 0.77102314\n",
      " 0.70736738 0.54097375 0.86579372 0.47500796 0.56531168 0.99994107\n",
      " 0.6391269  0.9419072  0.99295202 0.999835   0.82949309 0.99786675\n",
      " 0.9991632  0.92511226 0.56950747 0.09716313 0.45281507 0.87043738\n",
      " 0.62684597 0.80249154 0.9904534  0.99629922 0.19796811 1.\n",
      " 0.99883319 0.99998821 0.4955626  0.65786651 0.81505533 0.61766474\n",
      " 0.18888116 0.83737787 0.58139946 0.59550721 0.99995286 0.74311408\n",
      " 0.70819239 0.49557439 0.7919785  0.59990336 0.58684456 0.59846547\n",
      " 0.92534798 0.85240492 0.66324089 0.99619315 0.91035629 0.90709159\n",
      " 0.6900185  0.6564522  0.87143918 0.62155409 0.99968178 0.56779851\n",
      " 0.99982321 0.78402301 0.47030537 0.8765307  0.65497896 0.74475232\n",
      " 0.46259738 0.98703549 0.99972892 0.88053791 0.63600363 0.95344561\n",
      " 0.99997643 0.92546584 0.60868387 0.62780063 0.62368734 0.49236862\n",
      " 0.97332846 0.65019388 0.77642109 0.59313824 0.89407993 0.6361097\n",
      " 0.99268094 0.98122503 0.74478768 0.90375617 0.72134548 0.63537898\n",
      " 0.79019883 0.80903273 0.36284135 0.96888517 0.96215541 0.56817566\n",
      " 0.63662828 0.73753934 0.83905147 0.99997643 0.930852   0.83163813\n",
      " 0.73324926 0.87409101 0.74663807 0.40387993 0.8316617  0.79269744\n",
      " 0.7062595  0.80649876 0.99972892 0.99994107 0.49242755 0.89624854\n",
      " 0.78570839 0.9945549  0.74421017 0.64476057 0.98988768 0.91593103\n",
      " 0.74009688 0.72611878 0.75968508 0.98756585 0.95528422 0.85906396\n",
      " 0.78007472 0.70957135 0.34498568 0.75844756 0.77119992 0.29414122\n",
      " 0.99842069 0.9059955  0.89721499 0.89373814 0.8995486  0.7445166\n",
      " 0.66944029 0.87545818 0.94802409 0.96377008 0.99827926 0.99971714\n",
      " 0.9738824  0.55016677 0.71229389 0.58910745 0.54994284 0.4859335\n",
      " 0.5134772  0.99183236 0.76890167 0.99976428 0.81600999 0.40985539\n",
      " 0.46508421 0.70881705 0.99995286 0.34024774 0.7927328  0.68908742\n",
      " 0.97222059 0.99982321 0.98865016 0.99910427 0.89789857 0.60713991\n",
      " 0.4994166  0.97725317 0.39923627 0.46765354 0.35246974 0.6556979\n",
      " 0.89686141 0.68477377 0.98366471 0.72536448 0.99501456 0.99804354\n",
      " 0.40327884 0.97372918 0.99974071 0.99222129 0.99954035 0.99995286\n",
      " 0.99996464]\n",
      "349\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tabulate\n",
    "!pip3 install ReliefF\n",
    "score=fitness_score_values(x.values,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "s2XudtXTboAR"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(agent, train_X, test_X, train_Y, test_Y): \n",
    "    # compute classification accuracy of the given agents\n",
    "    fitness=0\n",
    "    number=0\n",
    "    # print(len(agent))\n",
    "    # print(len(score))\n",
    "    for i in range(len(agent)):\n",
    "        if agent[i]==1:\n",
    "            number=number+1\n",
    "            fitness=fitness+score[i]\n",
    "           \n",
    "    if number==0:\n",
    "      return 0\n",
    "    return fitness/number        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "rNqkKBRLcaGP"
   },
   "outputs": [],
   "source": [
    "def cal(agent): \n",
    "    # compute classification accuracy of the given agents\n",
    "    fitness=0\n",
    "    number=0\n",
    "    for i in range(len(agent)):\n",
    "        if agent[i]==1:\n",
    "            number=number+1\n",
    "            fitness=fitness+score[i]\n",
    "           \n",
    "    if number==0:\n",
    "     return 0,0\n",
    "    return fitness,number  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "PObwqfQMsQzX"
   },
   "outputs": [],
   "source": [
    "def initialize(popSize,dim):\n",
    "\tpopulation=np.zeros((popSize,dim))\n",
    "\tminn = 1\n",
    "\tmaxx = math.floor(0.8*dim)\n",
    "\tif maxx<minn:\n",
    "\t\tminn = maxx\n",
    "\n",
    "\tfor i in range(popSize):\n",
    "\t\trandom.seed(i**3 + 10 + time.time() ) \n",
    "\t\tno = random.randint(minn,maxx)\n",
    "\t\tif no == 0:\n",
    "\t\t\tno = 1\n",
    "\t\trandom.seed(time.time()+ 100)\n",
    "\t\tpos = random.sample(range(0,dim-1),no)\n",
    "\t\tfor j in pos:\n",
    "\t\t\tpopulation[i][j]=1\n",
    "\n",
    "\t\t# print(population[i])  \n",
    "\treturn population\n",
    "\n",
    " \n",
    "def fitness(solution, trainX, trainy, testX,testy):\n",
    "\tcols=np.flatnonzero(solution)\n",
    "\tval=1\n",
    "\tif np.shape(cols)[0]==0:\n",
    "\t\treturn val\t\n",
    "\tclf=KNeighborsClassifier(n_neighbors=5)\n",
    "\ttrain_data=trainX[:,cols]\n",
    "\ttest_data=testX[:,cols]\n",
    "\tclf.fit(train_data,trainy)\n",
    "\terror=1-clf.score(test_data,testy)\n",
    "\n",
    "\t#in case of multi objective  []\n",
    "\tfeatureRatio = (solution.sum()/np.shape(solution)[0])\n",
    "\tval=omega*error+(1-omega)*featureRatio\n",
    "\t# print(error,featureRatio,val)\n",
    "\treturn val\n",
    "\n",
    "def allfit(population, trainX,  trainy,testX, testy):\n",
    "\tx=np.shape(population)[0]\n",
    "\tacc=np.zeros(x)\n",
    "\tfor i in range(x):\n",
    "\t\tacc[i]=fitness(population[i],trainX,trainy,testX,testy)     \n",
    "\t\t#print(acc[i])\n",
    "\treturn acc\n",
    "\n",
    "\n",
    "def selectParentRoulette(popSize,fitness):\n",
    "    # Perform roulette wheel selection\n",
    "    maximum = sum([f for f in fitness])\n",
    "    selection_probs = [f/maximum for f in fitness]\n",
    "    return np.random.choice(len(fitness), p=selection_probs)\n",
    "\n",
    "\n",
    "def randomwalk(agent,agentFit):\n",
    "\tpercent = 30\n",
    "\tpercent /= 100\n",
    "\tneighbor = agent.copy()\n",
    "\tsize = np.shape(agent)[0]\n",
    "\tupper = int(percent*size)\n",
    "\tif upper <= 1 or upper>size:\n",
    "\t\tupper = size\n",
    "\tx = random.randint(1,upper)\n",
    "\tpos = random.sample(range(0,size - 1),x)\n",
    "\tfor i in pos:\n",
    "\t\tneighbor[i] = 1 - neighbor[i]\n",
    "\treturn neighbor\n",
    "\n",
    "def adaptiveBeta(agent,agentFit, trainX, trainy,testX,testy):\n",
    "\tbmin = 0.1 #parameter: (can be made 0.01)\n",
    "\tbmax = 1\n",
    "\tmaxIter = 10 # parameter: (can be increased )\n",
    "\tmaxIter = int(max(10,10*agentFit))\n",
    "\n",
    "\n",
    "\tfor curr in range(maxIter):\n",
    "\t\tneighbor = agent.copy()\n",
    "\t\tsize = np.shape(agent)[0]\n",
    "\t\tneighbor = randomwalk(neighbor,agentFit)\n",
    "\n",
    "\t\tbeta = bmin + (curr / maxIter)*(bmax - bmin)\n",
    "\t\tfor i in range(size):\n",
    "\t\t\trandom.seed( time.time() + i )\n",
    "\t\t\tif random.random() <= beta:\n",
    "\t\t\t\tneighbor[i] = agent[i]\n",
    "\t\tneighFit = fitness(neighbor,trainX,trainy,testX,testy)\n",
    "\t\tif neighFit <= agentFit:\n",
    "\t\t\tagent = neighbor.copy()\n",
    "\t\t\tagentFit = neighFit\n",
    "\treturn (agent,agentFit)\n",
    "\n",
    "#============================================================================\n",
    "def geneticAlgo(dataset,popSize,maxIter,randomstate):\n",
    "\n",
    "\t#--------------------------------------------------------------------\n",
    "\t(a,b)=np.shape(df)\n",
    "\tprint(a,b)\n",
    "\tdata = df.values[:,0:b-1]\n",
    "\t#print(data)\n",
    "\tlabel=target\n",
    "\n",
    "  \n",
    "\n",
    "\tprint(label)\n",
    "\tdimension = np.shape(data)[1] #solution dimension\n",
    "\t#---------------------------------------------------------------------\n",
    "\n",
    "\t# cross = 5\n",
    "\t# test_size = (1/cross)\n",
    "\tper=0.3\n",
    "\ttrainX, testX, trainy, testy = train_test_split(data, label ,stratify=label ,test_size=per,random_state=42) \n",
    "\n",
    "  \n",
    "\tx_axis = []\n",
    "\ty_axis = []\n",
    "\tpopulation = initialize(popSize,dimension)\n",
    "  \n",
    "\tprint(population)\n",
    "\tGBESTSOL = np.zeros(np.shape(population[0]))\n",
    "\tGBESTFIT = -1000\n",
    "\n",
    "\n",
    "\n",
    "\t\n",
    "\n",
    "\tstart_time = datetime.now()\n",
    "  \n",
    "\tfor currIter in range(1,maxIter):\n",
    "\t\tnewpop = population\n",
    "\t\t#newpop = np.zeros((popSize,dimension))\n",
    "\t\n",
    "\n",
    "\t\tobj_function=compute_fitness\n",
    "\t\tweight_acc = None\n",
    "\t\tobj=(obj_function, weight_acc)\n",
    "\t  \n",
    "\t\tpopulation,fitList=sort_agents(population,obj,trainX,trainy,testX,testy)\n",
    "\t\n",
    "\t  \n",
    "\n",
    "\t\tbestInx = np.argmax(fitList)\n",
    "\t\tfitBest = max(fitList)\n",
    "\t\tprint(currIter,'best:',fitBest,population[bestInx].sum())\n",
    "\t  \n",
    "\t\t# print(population[bestInx])\n",
    "\t\tif fitBest > GBESTFIT:\n",
    "\t\t\tGBESTSOL = population[bestInx].copy()\n",
    "\t\t\tGBESTFIT = fitBest\n",
    "\t\t#print(fitList)\n",
    "\t\tfor selectioncount in range(int(popSize/2)):\n",
    "\t\t\tparent1 = selectParentRoulette(popSize,fitList)\n",
    "\t\t\tparent2 = parent1\n",
    "\t\t\twhile parent2 == parent1:\n",
    "\t\t\t\trandom.seed(time.time())\n",
    "\t\t\t\t# parent2 = random.randint(0,popSize-1)\n",
    "\t\t\t\tparent2 = selectParentRoulette(popSize,fitList)\n",
    "\n",
    "\t\t\t\t# print(parent2)\n",
    "\t\t\t# print('parents:',parent1,parent2)\n",
    "\t\t\tparent1 = population[parent1].copy()\n",
    "\t\t\tparent2 = population[parent2].copy()\n",
    "\t\t\t#cross over between parent1 and parent2\n",
    "\t\t\tchild1 = parent1.copy()\n",
    "\t\t\tchild2 = parent2.copy()\n",
    "\t\t\tfor i in range(dimension):\n",
    "\t\t\t\trandom.seed(time.time())\n",
    "\t\t\t\tif random.uniform(0,1)<crossoverprob:\n",
    "\t\t\t\t\tchild1[i]=parent2[i]\n",
    "\t\t\t\t\tchild2[i]=parent1[i]\n",
    "\t\t\ti = selectioncount\n",
    "\t\t\tj = int(i+(popSize/2))\n",
    "\t\t\t# print(i,j)\n",
    "\t\t\tnewpop[i]=child1.copy()\n",
    "\t\t\tnewpop[j]=child2.copy()\n",
    "\t \n",
    "\n",
    "    \n",
    "\t\tmutationprob = muprobmin + (muprobmax - muprobmin)*(currIter/maxIter)\n",
    "\t\tfor i in range(popSize):\n",
    "\t\t\tfor k in range(1):\n",
    "\t\t\t\tfit,no=cal(newpop[i])\n",
    "\t\t\t\tfor j in range(dimension):\n",
    "\t\t\t\t\tif random.uniform(0,1)>mutationprob:\n",
    "\t\t\t\t\t \tcontinue\t\t\n",
    "\t\t\t\t\tif no==0 or newpop[i][j]==0 and score[j]>(fit/no):\n",
    "\t\t\t\t\t\tnewpop[i][j]=1\n",
    "\t\t\t\t\t\tfit=fit+score[j]\n",
    "\t\t\t\t\t\tno=no+1\n",
    "\t\t\t\t\tif newpop[i][j]==1 and score[j]<(fit/no):\n",
    "\t\t\t\t\t\tnewpop[i][j]=0\n",
    "\t\t\t\t\t\tfit=fit-score[j]\n",
    "\t\t\t\t\t\tno=no-1\n",
    "\t  \n",
    "\t\t\n",
    "\n",
    "      \n",
    "    \n",
    "\n",
    "\t\tpopulation = newpop.copy()\n",
    "\n",
    "\t# pyplot.plot(x_axis,y_axis)\n",
    "\t# pyplot.show()\n",
    "\n",
    "\t#test accuracy\n",
    "\tcols = np.flatnonzero(GBESTSOL)\n",
    "\tval = 1\n",
    "\tif np.shape(cols)[0]==0:\n",
    "\t\treturn GBESTSOL\n",
    "\tclf = KNeighborsClassifier(n_neighbors=5)\n",
    "\ttrain_data = trainX[:,cols]\n",
    "\ttest_data = testX[:,cols]\n",
    "\tclf.fit(train_data,trainy)\n",
    "\tval = clf.score(test_data,testy)\n",
    "\treturn GBESTSOL,val,test_data,testy,train_data,trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "P22yx0L7td7k"
   },
   "outputs": [],
   "source": [
    "popSize = 5\n",
    "maxIter = 5\n",
    "omega = 0.9\n",
    "crossoverprob = 0.8\n",
    "muprobmin = 0.01\n",
    "muprobmax = 0.05\n",
    "datasetList = [\"Dataset\"]\n",
    "randomstateList=[15,5,15,26,12,7,10,8,37,19,35,2,49,26,1,25,47,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "WX8beHjbth7i"
   },
   "outputs": [],
   "source": [
    "def ga_final_vector():\n",
    "  for datasetinx in range(1): \n",
    "    dataset=datasetList[datasetinx]\n",
    "    best_accuracy = -100\n",
    "    best_no_features = 100\n",
    "    best_answer = []\n",
    "    accuList = []\n",
    "    featList = []\n",
    "    for count in range(15):\n",
    "      if (dataset == \"WaveformEW\" or dataset == \"KrvskpEW\") : #and count>2 :\n",
    "        break\n",
    "      print(count)\n",
    "      answer,testAcc,testX,testy,trainX,trainy = geneticAlgo(dataset+\".csv\",popSize,maxIter,randomstateList[datasetinx])\n",
    "      print(testAcc,answer.sum())\n",
    "      accuList.append(testAcc)\n",
    "      featList.append(answer.sum())\n",
    "      if testAcc>=best_accuracy and answer.sum()<best_no_features:\n",
    "        best_accuracy = testAcc\n",
    "        best_no_features = answer.sum()\n",
    "        best_answer = answer.copy()\n",
    "        testX_final=testX\n",
    "        testy_final=testy\n",
    "        trainX_final=trainX\n",
    "        trainy_final=trainy\n",
    "      if testAcc>best_accuracy:\n",
    "        best_accuracy = testAcc\n",
    "        best_no_features = answer.sum()\n",
    "        best_answer = answer.copy()\n",
    "        testX_final=testX\n",
    "        testy_final=testy\n",
    "        trainX_final=trainX\n",
    "        trainy_final=trainy\n",
    "\n",
    "\n",
    "\n",
    "    print(dataset,\"best:\",best_accuracy,best_no_features,best_answer)\n",
    "    return best_answer,trainX_final,trainy_final,testX_final,testy_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLpXZMkOXjEL",
    "outputId": "4d27112c-fd17-4805-c3c6-690f44976c8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[0. 1. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "1 best: 0.31272317998257415 114.0\n",
      "2 best: 0.3173933247381369 112.0\n",
      "3 best: 0.3085841104730064 116.0\n",
      "4 best: 0.31214599079216937 124.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.945206983638959 112.0\n",
      "1\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[0. 0. 1. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [1. 1. 1. ... 1. 1. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]]\n",
      "1 best: 0.31384703373352146 15.0\n",
      "2 best: 0.3020023494352924 217.0\n",
      "3 best: 0.30308815948603346 226.0\n",
      "4 best: 0.30590318491559604 225.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4829252223564291 15.0\n",
      "2\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[1. 0. 1. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 1. 0.]]\n",
      "1 best: 0.3030456922165387 80.0\n",
      "2 best: 0.301117236429904 170.0\n",
      "3 best: 0.3028951084478177 184.0\n",
      "4 best: 0.305622371554517 181.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9660700560008785 181.0\n",
      "3\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[0. 1. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 1. 0.]]\n",
      "1 best: 0.3097862470682158 74.0\n",
      "2 best: 0.30943367786699133 135.0\n",
      "3 best: 0.3084215844946584 148.0\n",
      "4 best: 0.31361403643415336 97.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9405951465905348 97.0\n",
      "4\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 1. 1. 0.]\n",
      " [0. 1. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n",
      "1 best: 0.30726122211483503 43.0\n",
      "2 best: 0.30881379119959845 45.0\n",
      "3 best: 0.3109548365160512 46.0\n",
      "4 best: 0.315855727444115 51.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875260788404524 51.0\n",
      "5\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 1. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 1. 0.]]\n",
      "1 best: 0.3060608063361757 167.0\n",
      "2 best: 0.31042454885865106 101.0\n",
      "3 best: 0.3100070428546679 124.0\n",
      "4 best: 0.31397419724864944 139.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9617876358844845 139.0\n",
      "6\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[0. 0. 0. ... 1. 1. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 1. 0. 0.]]\n",
      "1 best: 0.30801824846144626 181.0\n",
      "2 best: 0.30972668383426866 71.0\n",
      "3 best: 0.3076373360398622 80.0\n",
      "4 best: 0.30851298301738994 110.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9325793345777973 71.0\n",
      "7\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[0. 0. 1. ... 0. 1. 0.]\n",
      " [1. 1. 0. ... 0. 1. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 1. 1. 0.]\n",
      " [1. 0. 1. ... 1. 0. 0.]]\n",
      "1 best: 0.3021113010833193 205.0\n",
      "2 best: 0.30343937218203415 127.0\n",
      "3 best: 0.30682842002589633 135.0\n",
      "4 best: 0.3090902557643846 139.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9561875480399693 139.0\n",
      "8\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 1. 0. 0.]]\n",
      "1 best: 0.30763814975411796 136.0\n",
      "2 best: 0.30850754833733013 125.0\n",
      "3 best: 0.3110374369091031 118.0\n",
      "4 best: 0.31188234303808476 135.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9597013286482925 135.0\n",
      "9\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[1. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "1 best: 0.35417562882866754 3.0\n",
      "2 best: 0.36031757213010407 2.0\n",
      "3 best: 0.3653356238482507 3.0\n",
      "4 best: 0.4294011106341179 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2934006807949929 5.0\n",
      "10\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]]\n",
      "1 best: 0.428105999591432 2.0\n",
      "2 best: 0.3021651620688006 41.0\n",
      "3 best: 0.30750307393859033 79.0\n",
      "4 best: 0.3111788401763533 108.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1036565279455364 2.0\n",
      "11\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 1. 0. 0.]]\n",
      "1 best: 0.3071034880165709 104.0\n",
      "2 best: 0.303008080378108 135.0\n",
      "3 best: 0.3043338307434953 118.0\n",
      "4 best: 0.30714091296093865 129.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953771823871747 129.0\n",
      "12\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[1. 0. 1. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 1. 0.]]\n",
      "1 best: 0.3038442228872667 151.0\n",
      "2 best: 0.3045007967445073 151.0\n",
      "3 best: 0.30649560812714166 152.0\n",
      "4 best: 0.30864941921027605 144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9605797738003733 144.0\n",
      "13\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[1. 1. 1. ... 0. 1. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]]\n",
      "1 best: 0.3080525368418938 148.0\n",
      "2 best: 0.30927110521842605 151.0\n",
      "3 best: 0.30996812038167093 151.0\n",
      "4 best: 0.3127120156260237 150.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9571757988360602 150.0\n",
      "14\n",
      "30356 350\n",
      "[ 8 10  2 ...  4 11  8]\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [1. 1. 0. ... 1. 1. 0.]\n",
      " [1. 0. 1. ... 1. 1. 0.]\n",
      " [0. 1. 1. ... 1. 0. 0.]]\n",
      "1 best: 0.3162446449272675 131.0\n",
      "2 best: 0.30667385683927395 171.0\n",
      "3 best: 0.30494612463974835 222.0\n",
      "4 best: 0.30769900386801236 210.0\n",
      "0.9557483254639288 131.0\n",
      "Dataset best: 0.9660700560008785 181.0 [0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "ga,trainX_final,trainy_final,testX_final,testy_final=ga_final_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from seaborn) (1.23.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from seaborn) (1.9.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from seaborn) (1.4.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn) (4.34.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mlxtend in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (0.20.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from mlxtend) (1.9.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from mlxtend) (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from mlxtend) (1.23.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from mlxtend) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from mlxtend) (49.2.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from mlxtend) (3.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (4.34.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (9.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from pandas>=0.24.2->mlxtend) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sksabbir/Library/Python/3.8/lib/python/site-packages (from scikit-learn>=1.0.2->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 10  2 ... 11  4  4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 8640x8640 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip3 install seaborn\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes_= np.array(['Nordic_walking', 'ascending_stairs', 'cycling','descending_stairs', 'ironing','lying', \n",
    "                   'rope_jumping', 'running','sitting', 'standing', 'vacuum_cleaning', 'walking'], dtype=object)\n",
    "!pip3 install mlxtend\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "clf=KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(trainX_final,trainy_final)\n",
    "y_pred = clf.predict(testX_final)\n",
    "print(y_pred)\n",
    "mat = confusion_matrix(testy_final, y_pred)\n",
    "\n",
    "# pd.DataFrame(testy_final).to_csv(\"testy.csv\")\n",
    "# pd.DataFrame(y_pred).to_csv(\"y_pred.csv\")\n",
    "# print(mat)\n",
    "res=sn.heatmap(mat, cmap='Greens', annot=True, fmt='d')\n",
    "\n",
    "plt.yticks([0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5,11.5], classes_,rotation=0,fontsize=10)\n",
    "plt.xticks([0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5,11.5], classes_,rotation=80,fontsize=10)\n",
    "\n",
    "\n",
    "plt.title('Confusion Matrix',fontsize=20)\n",
    "plt.xlabel(\"Predicted Label\",fontsize=17)\n",
    "plt.ylabel(\"True Label\",fontsize=17)\n",
    "plt.figure(figsize=(120,120))\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   Nordic_walking       0.96      1.00      0.98       882\n",
      " ascending_stairs       0.92      0.95      0.93       550\n",
      "          cycling       0.96      0.99      0.98       771\n",
      "descending_stairs       0.96      0.91      0.93       492\n",
      "          ironing       0.95      0.98      0.97      1119\n",
      "            lying       1.00      0.99      0.99       902\n",
      "     rope_jumping       0.98      0.96      0.97       231\n",
      "          running       1.00      0.98      0.99       460\n",
      "          sitting       0.97      0.99      0.98       868\n",
      "         standing       0.95      0.99      0.97       891\n",
      "  vacuum_cleaning       0.98      0.86      0.91       822\n",
      "          walking       0.98      0.97      0.98      1119\n",
      "\n",
      "         accuracy                           0.97      9107\n",
      "        macro avg       0.97      0.96      0.96      9107\n",
      "     weighted avg       0.97      0.97      0.97      9107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sksabbir/Library/Python/3.8/lib/python/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classes_= ['Nordic_walking', 'ascending_stairs', 'cycling','descending_stairs', 'ironing','lying', \n",
    "                   'rope_jumping', 'running','sitting', 'standing', 'vacuum_cleaning', 'walking']\n",
    "clf=KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(trainX_final,trainy_final)\n",
    "y_pred = clf.predict(testX_final)\n",
    "report=classification_report(testy_final,y_pred,target_names=classes_)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FINAL_CODE_HAR.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
